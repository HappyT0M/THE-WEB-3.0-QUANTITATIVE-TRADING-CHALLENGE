import datetime
import os
import glob
import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
import talib    # ç”¨äºè®¡ç®—æŠ€æœ¯æŒ‡æ ‡
import torch

# ======================
# è·¯å¾„ä¸å¸¸é‡å®šä¹‰
# ======================
# Kaggle æ•°æ®è·¯å¾„ï¼ˆè¯·æ ¹æ®ä½ çš„å®é™…ç›®å½•è°ƒæ•´ï¼Œå¦‚æœåœ¨æœ¬åœ°è¯·ä¿®æ”¹ä¸ºæœ¬åœ°è·¯å¾„ï¼‰
DATA_PATH = "/kaggle/input/avenir-hku-web/kline_data/train_data"  # âš ï¸ æœ¬åœ°è¯·æ”¹æˆä½ çš„ parquet æ–‡ä»¶æ‰€åœ¨ç›®å½•
SUBMISSION_ID_PATH = "/kaggle/input/avenir-hku-web/submission_id.csv"  # âš ï¸ æœ¬åœ°è¯·æ”¾ç½® submission_id.csv
OUTPUT_SUBMIT_PATH = "/kaggle/working/submit.csv"  # Kaggle ä¸Šçš„è¾“å‡ºè·¯å¾„ï¼Œæœ¬åœ°å¯æ”¹æˆ ./submit.csv

# æ¨¡å‹è®­ç»ƒä½¿ç”¨çš„èµ·å§‹æ—¶é—´
START_DATETIME = datetime.datetime(2021, 3, 1, 0, 0, 0)

# ç›®æ ‡ï¼šé¢„æµ‹æœªæ¥å¤šå°‘ä¸ª15åˆ†é’Ÿåçš„æ”¶ç›Šï¼ˆå¦‚ 96 = 1å¤© * 96ä¸ª15åˆ†é’Ÿï¼‰
TARGET_HORIZON = 96

# è®¾å¤‡é…ç½®
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"âœ… ä½¿ç”¨è®¡ç®—è®¾å¤‡: {DEVICE}")


class OptimizedModel:
    def __init__(self):
        self.data_path = DATA_PATH
        self.submission_id_path = SUBMISSION_ID_PATH
        self.start_datetime = START_DATETIME
        self.target_horizon = TARGET_HORIZON
        self.use_gpu = USE_GPU
        print(f"âœ… åˆå§‹åŒ–æ¨¡å‹ï¼Œæ•°æ®è·¯å¾„: {self.data_path}")
        print(f"ğŸ” æ˜¯å¦å¯ç”¨ GPU è®­é€ŸåŠ é€Ÿ: {'æ˜¯' if self.use_gpu else 'å¦'}")

    def get_all_symbols(self):
        files = glob.glob(os.path.join(self.data_path, "*.parquet"))
        symbols = [os.path.basename(f).split(".")[0] for f in files]
        print(f"ğŸ” å‘ç° {len(symbols)} ä¸ªäº¤æ˜“å¯¹ï¼ˆsymbolï¼‰")
        return symbols

    def load_all_data(self, symbols):
        dfs = []
        valid_symbols = []
        failed_symbols = []
        for s in symbols:
            file_path = os.path.join(self.data_path, f"{s}.parquet")
            if not os.path.exists(file_path):
                print(f"[!] æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                failed_symbols.append(s)
                continue

            try:
                df = pd.read_parquet(file_path)
                if 'timestamp' not in df.columns:
                    print(f"[!] {s} ç¼ºå°‘ timestamp åˆ—")
                    failed_symbols.append(s)
                    continue
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df = df.set_index('timestamp').sort_index()
                df = df.astype(np.float64)

                required_cols = ['open_price', 'high_price', 'low_price', 'close_price', 'volume', 'amount', 'buy_volume']
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    print(f"[!] {s} ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                    failed_symbols.append(s)
                    continue

                df = df[df.index >= self.start_datetime]

                future_return = df['close_price'].shift(-self.target_horizon) / df['close_price'] - 1
                df['target'] = future_return
                df['target'] = df['target'].replace([np.inf, -np.inf], np.nan)

                df['rsi'] = talib.momentum.RSIIndicator(df['close_price'], window=14).rsi()
                macd = talib.trend.MACD(df['close_price'])
                df['macd'] = macd.macd_diff()
                df['atr'] = talib.volatility.AverageTrueRange(df['high_price'], df['low_price'], df['close_price'], window=14).average_true_range()
                bb = talib.volatility.BollingerBands(df['close_price'], window=20, window_dev=2)
                df['bb_upper'] = bb.bollinger_hband()
                df['bb_lower'] = bb.bollinger_lband()
                df['bb_width'] = df['bb_upper'] - df['bb_lower']
                df['1h_momentum'] = df['close_price'].pct_change(periods=4)
                df['vol_momentum'] = df['volume'].pct_change(periods=96)
                df['amount_sum'] = df['amount'].rolling(window=7 * 96).sum()
                df['4h_momentum'] = df['close_price'].pct_change(periods=16)
                df['7d_momentum'] = df['close_price'].pct_change(periods=7 * 96)

                for col in ['rsi', 'macd', 'atr', 'bb_width', '1h_momentum', 'vol_momentum', 'amount_sum', '4h_momentum', '7d_momentum']:
                    if col in df.columns:
                        df[col] = df[col].replace([np.inf, -np.inf], np.nan)

                df = df.dropna(subset=['target'])
                df['symbol'] = s

                dfs.append(df)
                valid_symbols.append(s)
                print(f"âœ… åŠ è½½æˆåŠŸ: {s}, shape={df.shape}")
            except Exception as e:
                print(f"[!] åŠ è½½ {s} å‡ºé”™: {e}")
                failed_symbols.append(s)

        print(f"ğŸ” æ€»è®¡ï¼šæˆåŠŸåŠ è½½ {len(valid_symbols)} ä¸ª symbolï¼Œå¤±è´¥ {len(failed_symbols)} ä¸ª")
        return valid_symbols, dfs

    def train(self, dfs, valid_symbols):
        full_df = pd.concat(dfs, axis=0).sort_index()
        if full_df.empty:
            print("[!] é”™è¯¯ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ç”¨äºè®­ç»ƒï¼")
            return None

        if 'symbol' not in full_df.columns:
            raise ValueError("full_df ä¸­ç¼ºå°‘ 'symbol' åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®åŠ è½½éƒ¨åˆ†æ˜¯å¦ä¿ç•™äº† symbol åˆ—")

        feature_cols = [
            '4h_momentum', '7d_momentum', 'amount_sum', 'vol_momentum',
            'atr', 'macd', 'bb_width', '1h_momentum'
        ]
        available_features = [f for f in feature_cols if f in full_df.columns]
        X = full_df[available_features]
        y = full_df['target']

        combined_xy = pd.concat([X, y], axis=1)
        combined_xy = combined_xy.replace([np.inf, -np.inf], np.nan).dropna()

        X = combined_xy[available_features]
        y = combined_xy['target']

        print(f"âœ… æ¸…ç†åè®­ç»ƒæ•°æ®: X shape={X.shape}, y shape={y.shape}")

        # æ ‡å‡†åŒ–
        X_scaled = StandardScaler().fit_transform(X)

        # è®¾ç½® tree_method: GPU åŠ é€Ÿ or CPU
        tree_method = 'gpu_hist' if self.use_gpu else 'hist'

        model = xgb.XGBRegressor(
            objective='reg:squarederror',
            n_estimators=500,
            max_depth=10,
            learning_rate=0.05,
            subsample=0.9,
            tree_method=tree_method,  # âœ… GPU åŠ é€Ÿï¼š'gpu_hist'ï¼Œå¦åˆ™ 'hist'
            random_state=42
        )
        model.fit(X_scaled, y)

        y_pred = model.predict(X_scaled)

        result_df = combined_xy.copy()
        result_df['y_pred'] = y_pred

        if 'symbol' not in result_df.columns:
            raise ValueError("result_df ä¸­ç¼ºå°‘ 'symbol' åˆ—ï¼Œæ— æ³•æ„é€  id")

        result_df['id'] = result_df.index.strftime("%Y%m%d%H%M%S") + "_" + result_df['symbol']
        result_df = result_df[['id', 'y_pred']]
        result_df.columns = ['id', 'predict_return']
        result_df['predict_return'] = result_df['predict_return'].clip(-1, 1)

        print(f"âœ… æ„é€ å®Œæˆï¼šresult_df åŒ…å« {len(result_df)} æ¡è®°å½•")
        return result_df

    def generate_submission(self, predictions_df):
        submission_ids = pd.read_csv(self.submission_id_path)
        if 'id' not in submission_ids.columns:
            raise ValueError("submission_id.csv å¿…é¡»åŒ…å« 'id' åˆ—")

        if 'id' not in predictions_df.columns or 'predict_return' not in predictions_df.columns:
            raise ValueError("é¢„æµ‹ç»“æœ DataFrame å¿…é¡»åŒ…å« 'id' å’Œ 'predict_return' åˆ—")

        final_submission = submission_ids.merge(
            predictions_df[['id', 'predict_return']],
            on='id',
            how='left'
        )
        final_submission['predict_return'] = final_submission['predict_return'].fillna(0.0)

        final_submission = final_submission[['id', 'predict_return']]
        final_submission.to_csv(OUTPUT_SUBMIT_PATH, index=False)
        print(f"âœ… æäº¤æ–‡ä»¶å·²ä¿å­˜è‡³: {OUTPUT_SUBMIT_PATH}")
# ======================
# 4. ä¸»ç¨‹åºå…¥å£
# ======================
if __name__ == "__main__":
    model = OptimizedModel()
    symbols = model.get_all_symbols()
    valid_symbols, dfs = model.load_all_data(symbols)

    if not valid_symbols:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œé€€å‡º")
    else:
        print(f"ğŸ” å°†ä½¿ç”¨ {len(valid_symbols)} ä¸ªæœ‰æ•ˆ symbol è¿›è¡Œè®­ç»ƒ")
        result_df = model.train(dfs, valid_symbols)
        if result_df is not None:
            model.generate_submission(result_df)